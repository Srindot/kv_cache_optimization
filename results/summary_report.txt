============================================================
KV CACHE OPTIMIZATION EXPERIMENT SUMMARY
============================================================

Experiment: Baseline
----------------------------------------
Model: gpt2-large
Generation Length: 100
Device: cuda
Average Timing: 50.76 ms/token
Peak VRAM: 3.03 GB
Total Tokens: 100
Metadata:
  total_experiment_time: 5.231493234634399

Experiment: Attention Sink
----------------------------------------
Model: gpt2-large
Generation Length: 100
Device: cuda
Average Timing: 45.96 ms/token
Peak VRAM: 3.03 GB
Total Tokens: 99
Metadata:
  total_experiment_time: 4.714186191558838

Experiment: MiniCache
----------------------------------------
Model: gpt2-large
Generation Length: 100
Device: cuda
Average Timing: 48.29 ms/token
Peak VRAM: 3.03 GB
Total Tokens: 100
Metadata:
  total_experiment_time: 4.980290651321411

Experiment: H2O
----------------------------------------
Model: gpt2-large
Generation Length: 100
Device: cuda
Average Timing: 111.69 ms/token
Peak VRAM: 120.00 GB
Total Tokens: 2
Metadata:
  total_experiment_time: 0.22374224662780762

Experiment: PyramidKV
----------------------------------------
Model: gpt2-large
Generation Length: 100
Device: cuda
Average Timing: 162.60 ms/token
Peak VRAM: 720.00 GB
Total Tokens: 2
Metadata:
  total_experiment_time: 0.3255927562713623

Experiment: Quantization-8bit
----------------------------------------
Model: gpt2-large
Generation Length: 100
Device: cuda
Average Timing: 217.17 ms/token
Peak VRAM: 300.00 GB
Total Tokens: 2
Metadata:
  total_experiment_time: 0.4347569942474365

Experiment: Quantization-4bit
----------------------------------------
Model: gpt2-large
Generation Length: 100
Device: cuda
Average Timing: 215.14 ms/token
Peak VRAM: 150.00 GB
Total Tokens: 2
Metadata:
  total_experiment_time: 0.43058133125305176

Experiment: SlidingWindow-128
----------------------------------------
Model: gpt2-large
Generation Length: 100
Device: cuda
Average Timing: 201.41 ms/token
Peak VRAM: 1256.00 GB
Total Tokens: 2
Metadata:
  total_experiment_time: 0.4031062126159668

Experiment: GQA-4groups
----------------------------------------
Model: gpt2-large
Generation Length: 100
Device: cuda
Average Timing: 192.74 ms/token
Peak VRAM: 1110.00 GB
Total Tokens: 2
Metadata:
  total_experiment_time: 0.3858518600463867

PERFORMANCE COMPARISON (vs Baseline)
----------------------------------------
Attention Sink:
  Timing Speedup: 1.10x
  VRAM Reduction: 0.0%

MiniCache:
  Timing Speedup: 1.05x
  VRAM Reduction: 0.0%

H2O:
  Timing Speedup: 0.45x
  VRAM Reduction: -3857.8%

PyramidKV:
  Timing Speedup: 0.31x
  VRAM Reduction: -23646.6%

Quantization-8bit:
  Timing Speedup: 0.23x
  VRAM Reduction: -9794.4%

Quantization-4bit:
  Timing Speedup: 0.24x
  VRAM Reduction: -4847.2%

SlidingWindow-128:
  Timing Speedup: 0.25x
  VRAM Reduction: -41324.5%

GQA-4groups:
  Timing Speedup: 0.26x
  VRAM Reduction: -36509.3%
